{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202072d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# Crop Disease Detection using Deep Learning\n",
    "# Using MobileNet and InceptionV3 (Transfer Learning)\n",
    "# ==============================================\n",
    "\n",
    "# 1. Imports and Setup\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, InceptionV3\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 2. Leaf Segmentation and Preprocessing Function\n",
    "def preprocess_input_image(img):\n",
    "    # Convert to float32\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "\n",
    "    # Resize to 224x224\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "# 3. Data Paths (placeholders for PlantVillage dataset)\n",
    "# Stage 1 (Crop Type) data directory (each subfolder is a crop type)\n",
    "crop_data_dir = '/content/drive/MyDrive/Dataset/crop'\n",
    "# Stage 2 (Disease) data directory: each subfolder is a crop, containing disease subfolders\n",
    "disease_data_dir = '/content/drive/MyDrive/Dataset/disease'\n",
    "\n",
    "# 4. ImageDataGenerator Setup (augmentation + preprocessing)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,               # 80-20 split\n",
    "    preprocessing_function=preprocess_input_image\n",
    ")\n",
    "\n",
    "# 5. Stage 1: Crop Classification Model (MobileNetV2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    crop_data_dir,\n",
    "    target_size=(224, 224),            # initial size for segmentation (cropping to 224 later)\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    crop_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "num_crops = train_generator.num_classes  # number of crop classes\n",
    "\n",
    "# Building MobileNetV2 model for crop classification\n",
    "base_model_crop = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "for layer in base_model_crop.layers:\n",
    "    layer.trainable = False\n",
    "x = base_model_crop.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)  # dropout to avoid overfitting\n",
    "output_crops = Dense(num_crops, activation='softmax')(x)\n",
    "model_crop = Model(inputs=base_model_crop.input, outputs=output_crops)\n",
    "\n",
    "model_crop.compile(optimizer=Adam(),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Train the crop classification model\n",
    "history_crop = model_crop.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Plot of training & validation accuracy and loss for crop model\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_crop.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_crop.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Crop Classification Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_crop.history['loss'], label='Train Loss')\n",
    "plt.plot(history_crop.history['val_loss'], label='Val Loss')\n",
    "plt.title('Crop Classification Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6. Stage 2: Disease Classification Models (InceptionV3 per Crop)\n",
    "disease_datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input_image\n",
    ")\n",
    "\n",
    "# Get list of crop types from the crop generator\n",
    "crop_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "for crop in crop_names:\n",
    "    print(f\"\\n--- Training disease model for crop: {crop} ---\")\n",
    "    # Paths to this crop's disease images\n",
    "    crop_disease_path = os.path.join(disease_data_dir, crop)\n",
    "\n",
    "    train_gen = disease_datagen.flow_from_directory(\n",
    "        crop_disease_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_gen = disease_datagen.flow_from_directory(\n",
    "        crop_disease_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=True\n",
    "    )\n",
    "    num_diseases = train_gen.num_classes\n",
    "\n",
    "    # Build InceptionV3 model for disease classification (crop-specific)\n",
    "    base_model_disease = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model_disease.layers:\n",
    "        layer.trainable = False\n",
    "    y = base_model_disease.output\n",
    "    y = GlobalAveragePooling2D()(y)\n",
    "    y = Dropout(0.5)(y)\n",
    "    output_diseases = Dense(num_diseases, activation='softmax')(y)\n",
    "    model_disease = Model(inputs=base_model_disease.input, outputs=output_diseases)\n",
    "\n",
    "    model_disease.compile(optimizer=Adam(),\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    # Train the disease classification model for this crop\n",
    "    history_disease = model_disease.fit(\n",
    "        train_gen,\n",
    "        epochs=10,\n",
    "        validation_data=val_gen\n",
    "    )\n",
    "\n",
    "    # Plot training & validation accuracy and loss for this disease model\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_disease.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history_disease.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'{crop.capitalize()} Disease Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_disease.history['loss'], label='Train Loss')\n",
    "    plt.plot(history_disease.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'{crop.capitalize()} Disease Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec77a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving models \n",
    "model_crop.save(\"/content/drive/MyDrive/Dataset/models/crop_model.h5\")\n",
    "model_disease.save(f\"/content/drive/MyDrive/Dataset/models/{crop}_disease_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d4b3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "crop_model = load_model(\"/content/drive/MyDrive/Dataset/models/crop_model.h5\")\n",
    "\n",
    "disease_models = {}\n",
    "for crop in [\"Potato\",\"Rice\",\"Cashew\",\"Potato\",\"Tomato\"]:\n",
    "    path = f\"/content/drive/MyDrive/Dataset/models/{crop}_disease_model.h5\"\n",
    "    disease_models[crop] = load_model(path)\n",
    "\n",
    "def preprocess_input_image(img):\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    return img\n",
    "\n",
    "def predict_crop_and_disease(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Preprocess\n",
    "    processed = preprocess_input_image(img)\n",
    "    processed = np.expand_dims(processed, axis=0)\n",
    "\n",
    "    # 1️⃣ Predict crop\n",
    "    crop_pred = crop_model.predict(processed)[0]\n",
    "    crop_index = np.argmax(crop_pred)\n",
    "    crop_label = list(train_generator.class_indices.keys())[crop_index]\n",
    "    print(\"Predicted Crop:\", crop_label)\n",
    "\n",
    "    # 2️⃣ Predict disease using its model\n",
    "    disease_model = disease_models[crop_label]\n",
    "    disease_pred = disease_model.predict(processed)[0]\n",
    "    disease_index = np.argmax(disease_pred)\n",
    "\n",
    "    # Get disease labels\n",
    "    disease_path = f\"/content/drive/MyDrive/Dataset/disease/{crop_label}\"\n",
    "    disease_classes = sorted(os.listdir(disease_path))\n",
    "\n",
    "    disease_label = disease_classes[disease_index]\n",
    "    print(\"Predicted Disease:\", disease_label)\n",
    "\n",
    "    return crop_label, disease_label\n",
    "\n",
    "#Testing model by providing a leaf image of potato\n",
    "predict_crop_and_disease(\"/content/healthy_potato_leaf.jpeg\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
